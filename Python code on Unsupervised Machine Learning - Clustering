Python code on Unsupervised Machine Learning - The Elbow technique, k-mean clustering 

Importing libraries and data and renaming columns
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt
import os
import sklearn
from sklearn.cluster import KMeans 
%matplotlib inline
path = '/Users/ronaldcameron/Documents/Data Analytics/Achievement 6 - Data/Data/df_all.pkl'
# Import the ecommerce data

df = pd.read_csv(os.path.join(path, '/Users/ronaldcameron/Documents/Data Analytics/Achievement 6 - Data/sales_pivot.csv'))
df_all = pd.read_pickle(r'/Users/ronaldcameron/Documents/Data Analytics/Achievement 6 - Data/Data/df_all.pkl')
df_all.shape
(11985284, 18)
df.columns
Index(['Sales by Month', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',
       '11', '12'],
      dtype='object')
df_all.columns
Index(['order_id', 'customer_id', 'order_status',
       'order_delivered_customer_date', 'payment_value', 'product_id',
       'seller_id', 'price', 'product_category_name', 'product_photos_qty',
       'customer_unique_id', 'customer_zip_code_prefix', 'customer_city',
       'customer_state', 'geolocation_lat', 'geolocation_lng',
       'geolocation_city', 'geolocation_state'],
      dtype='object')
df_all.head
<bound method NDFrame.head of                                   order_id                       customer_id  \
0         e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   
1         e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   
2         e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   
3         e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   
4         e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   
...                                    ...                               ...   
11985279  cfa78b997e329a5295b4ee6972c02979  a2f7428f0cafbc8e59f20e1444b67315   
11985280  cfa78b997e329a5295b4ee6972c02979  a2f7428f0cafbc8e59f20e1444b67315   
11985281  cfa78b997e329a5295b4ee6972c02979  a2f7428f0cafbc8e59f20e1444b67315   
11985282  cfa78b997e329a5295b4ee6972c02979  a2f7428f0cafbc8e59f20e1444b67315   
11985283  cfa78b997e329a5295b4ee6972c02979  a2f7428f0cafbc8e59f20e1444b67315   

         order_status order_delivered_customer_date  payment_value  \
0           delivered           2017-10-10 21:25:13          18.12   
1           delivered           2017-10-10 21:25:13          18.12   
2           delivered           2017-10-10 21:25:13          18.12   
3           delivered           2017-10-10 21:25:13          18.12   
4           delivered           2017-10-10 21:25:13          18.12   
...               ...                           ...            ...   
11985279    delivered           2018-01-26 15:45:14          71.04   
11985280    delivered           2018-01-26 15:45:14          71.04   
11985281    delivered           2018-01-26 15:45:14          71.04   
11985282    delivered           2018-01-26 15:45:14          71.04   
11985283    delivered           2018-01-26 15:45:14          71.04   

                                product_id                         seller_id  \
0         87285b34884572647811a353c7ac498a  3504c0cb71d7fa48d967e0e4c94d59d9   
1         87285b34884572647811a353c7ac498a  3504c0cb71d7fa48d967e0e4c94d59d9   
2         87285b34884572647811a353c7ac498a  3504c0cb71d7fa48d967e0e4c94d59d9   
3         87285b34884572647811a353c7ac498a  3504c0cb71d7fa48d967e0e4c94d59d9   
4         87285b34884572647811a353c7ac498a  3504c0cb71d7fa48d967e0e4c94d59d9   
...                                    ...                               ...   
11985279  3d2c44374ee42b3003a470f3e937a2ea  ce248b21cb2adc36282ede306b7660e5   
11985280  3d2c44374ee42b3003a470f3e937a2ea  ce248b21cb2adc36282ede306b7660e5   
11985281  3d2c44374ee42b3003a470f3e937a2ea  ce248b21cb2adc36282ede306b7660e5   
11985282  3d2c44374ee42b3003a470f3e937a2ea  ce248b21cb2adc36282ede306b7660e5   
11985283  3d2c44374ee42b3003a470f3e937a2ea  ce248b21cb2adc36282ede306b7660e5   

          price  product_category_name  product_photos_qty  \
0         29.99  utilidades_domesticas                 4.0   
1         29.99  utilidades_domesticas                 4.0   
2         29.99  utilidades_domesticas                 4.0   
3         29.99  utilidades_domesticas                 4.0   
4         29.99  utilidades_domesticas                 4.0   
...         ...                    ...                 ...   
11985279  55.90  instrumentos_musicais                 2.0   
11985280  55.90  instrumentos_musicais                 2.0   
11985281  55.90  instrumentos_musicais                 2.0   
11985282  55.90  instrumentos_musicais                 2.0   
11985283  55.90  instrumentos_musicais                 2.0   

                        customer_unique_id  customer_zip_code_prefix  \
0         7c396fd4830fd04220f754e42b4e5bff                      3149   
1         7c396fd4830fd04220f754e42b4e5bff                      3149   
2         7c396fd4830fd04220f754e42b4e5bff                      3149   
3         7c396fd4830fd04220f754e42b4e5bff                      3149   
4         7c396fd4830fd04220f754e42b4e5bff                      3149   
...                                    ...                       ...   
11985279  a49e8e11e850592fe685ae3c64b40eca                     83870   
11985280  a49e8e11e850592fe685ae3c64b40eca                     83870   
11985281  a49e8e11e850592fe685ae3c64b40eca                     83870   
11985282  a49e8e11e850592fe685ae3c64b40eca                     83870   
11985283  a49e8e11e850592fe685ae3c64b40eca                     83870   

             customer_city customer_state  geolocation_lat  geolocation_lng  \
0                sao paulo             SP       -23.574809       -46.587471   
1                sao paulo             SP       -23.578333       -46.587123   
2                sao paulo             SP       -23.575033       -46.587451   
3                sao paulo             SP       -23.580054       -46.586673   
4                sao paulo             SP       -23.576281       -46.587276   
...                    ...            ...              ...              ...   
11985279  campo do tenente             PR       -25.976613       -49.682770   
11985280  campo do tenente             PR       -25.984320       -49.685323   
11985281  campo do tenente             PR       -25.981080       -49.682970   
11985282  campo do tenente             PR       -25.981102       -49.682042   
11985283  campo do tenente             PR       -25.986294       -49.684537   

          geolocation_city geolocation_state  
0                sao paulo                SP  
1                sao paulo                SP  
2                sao paulo                SP  
3                sao paulo                SP  
4                sao paulo                SP  
...                    ...               ...  
11985279  campo do tenente                PR  
11985280  campo do tenente                PR  
11985281  campo do tenente                PR  
11985282  campo do tenente                PR  
11985283  campo do tenente                PR  

[11985284 rows x 18 columns]>
df_all = df_all.drop(columns = ['product_id', 'geolocation_city', 'geolocation_state', 'customer_city', 'customer_state','geolocation_lat','geolocation_lng','customer_unique_id','product_category_name','seller_id','product_id']) 
df_all.columns
Index(['order_id', 'customer_id', 'order_status',
       'order_delivered_customer_date', 'payment_value', 'price',
       'product_photos_qty', 'customer_zip_code_prefix'],
      dtype='object')
df_all = df_all.drop(columns = ['order_id','customer_id','order_status','order_delivered_customer_date'])
# Check for missing values

df_all.isnull().sum()
payment_value                    0
price                            0
product_photos_qty          170407
customer_zip_code_prefix         0
dtype: int64
df_all['product_photos_qty'].fillna("0", inplace=True)
2. The elbow technique
num_cl = range(1, 10) # Defines the range of potential clusters in the data.
kmeans = [KMeans(n_clusters=i) for i in num_cl] # Defines k-means clusters in the range assigned above.
score = [kmeans[i].fit(df_all).score(df_all) for i in range(len(kmeans))] # Creates a score that represents 
# a rate of variation for the given cluster option.

score
/Users/ronaldcameron/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
/Users/ronaldcameron/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
/Users/ronaldcameron/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
/Users/ronaldcameron/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
/Users/ronaldcameron/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
/Users/ronaldcameron/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
/Users/ronaldcameron/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
/Users/ronaldcameron/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
/Users/ronaldcameron/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
[-9000276055865247.0,
 -1643599937656101.5,
 -582471684420477.4,
 -392286531318314.7,
 -244278773978124.6,
 -185946705168892.2,
 -135039584849844.78,
 -96505257580817.08,
 -74773076602607.16]
# Plot the elbow curve using PyLab.

pl.plot(num_cl,score)
pl.xlabel('Number of Clusters')
pl.ylabel('Score')
pl.title('Elbow Curve')
pl.show()

There's a large jump from two to three on the x-axis, but after that, the curve straightens out. This means that the optimal count for your clusters is three.
3. k-means clustering
# Create the k-means object.
from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=3)
kmeans.fit(df_all) 
/Users/ronaldcameron/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(

KMeans
KMeans(n_clusters=3)
df_all['clusters'] = kmeans.fit_predict(df_all)
/Users/ronaldcameron/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
df_all.head
<bound method NDFrame.head of           payment_value  price product_photos_qty  customer_zip_code_prefix  \
0                 18.12  29.99                4.0                      3149   
1                 18.12  29.99                4.0                      3149   
2                 18.12  29.99                4.0                      3149   
3                 18.12  29.99                4.0                      3149   
4                 18.12  29.99                4.0                      3149   
...                 ...    ...                ...                       ...   
11985279          71.04  55.90                2.0                     83870   
11985280          71.04  55.90                2.0                     83870   
11985281          71.04  55.90                2.0                     83870   
11985282          71.04  55.90                2.0                     83870   
11985283          71.04  55.90                2.0                     83870   

          clusters  
0                0  
1                0  
2                0  
3                0  
4                0  
...            ...  
11985279         1  
11985280         1  
11985281         1  
11985282         1  
11985283         1  

[11985284 rows x 5 columns]>
df_all['clusters'].value_counts()
0    5836480
2    3878337
1    2270467
Name: clusters, dtype: int64
# Plot the clusters for the "Payment" and "Price" variables.

plt.figure(figsize=(12,8))
ax = sns.scatterplot(x=df_all['payment_value'], y=df_all['price'], hue=kmeans.labels_, s=100) 


ax.grid(False) 
plt.xlabel('Payment') # Label x-axis.
plt.ylabel('Price') # Label y-axis.
plt.show()

# Plot the clusters for the "Quantity of Photos" and "Price" variables.

plt.figure(figsize=(12,8))
ax = sns.scatterplot(x=df_all['customer_zip_code_prefix'], y=df_all['payment_value'], hue=kmeans.labels_, s=100)

ax.grid(False) 
plt.xlabel('Zip Code') 
plt.ylabel('Payment Value') 
plt.show()

Due to the limited number of numerical value columns in my dataset, I had to utilize the Payment Value column twice. However, when comparing the Payment Value to the Price column, the resulting clusters lacked clear distinctions and did not provide meaningful insights. On the other hand, analyzing the relationship between Payment Value and Zip Code yielded more distinct patterns in my specific dataset. Ultimately, clustering was not particularly helpful in analyzing my data.
df_all.loc[df_all['clusters'] == 2, 'cluster'] = 'dark purple'
df_all.loc[df_all['clusters'] == 1, 'cluster'] = 'purple'
df_all.loc[df_all['clusters'] == 0, 'cluster'] = 'pink'
df_all.groupby('cluster').agg({'price':['mean', 'median'], 
                         'payment_value':['mean', 'median']})
price	payment_value
mean	median	mean	median
cluster				
dark purple	126.435659	79.61	181.700765	116.45
pink	114.970264	69.90	161.140100	102.23
purple	127.767385	79.00	190.763302	119.08
In the future, the Payment Value vs Zip Code graph has the potential to be valuable in determining which area generates higher revenue. By analyzing the relationship between payment values and zip codes, we can gain insights into geographical patterns and identify regions that contribute more significantly to overall sales.
 
