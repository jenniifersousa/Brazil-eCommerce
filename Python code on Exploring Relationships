Python code on Importing Visualization libratires, Data Cleaning, Exploring Relationships Correlations 


#Importing Libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib
import os
import pickle
import nbformat
from nbconvert import PythonExporter
#Importing Dadaframe
df_data = pd.read_pickle(r'/Users/ronaldcameron/Documents/Data Analytics/Achievement 6 - Data/df_date.pkl')
df_all = pd.read_pickle(r'/Users/ronaldcameron/Documents/Data Analytics/Achievement 6 - Data/df_all.pkl')
#Importing Category Names
df_cat = pd.read_excel(r'/Users/ronaldcameron/Documents/Data Analytics/Achievement 6 - Data/Data/ecommerce_brazil.xlsm', sheet_name = 'product_category')
df_data.columns 
Index(['order_delivered_customer_date', 'Day', 'Month', 'Year'], dtype='object')
df_all.columns
Index(['order_id', 'customer_id', 'order_status',
       'order_delivered_customer_date', 'payment_value', 'product_id',
       'seller_id', 'price', 'product_category_name', 'product_photos_qty',
       'customer_unique_id', 'customer_zip_code_prefix', 'customer_city',
       'customer_state', 'geolocation_lat', 'geolocation_lng',
       'geolocation_city', 'geolocation_state'],
      dtype='object')
columns_to_drop = ['order_status','customer_zip_code_prefix','seller_id','geolocation_city','geolocation_state']
df = df_all.drop(columns_to_drop, axis=1)
#Droping Duplicates
df_data = df_data.drop_duplicates()
df1 = df.drop_duplicates()
# Split the original DataFrames into chunks since my kernel kept dying
chunk_size = 1000000  
df1_chunks = [df1[i:i+chunk_size] for i in range(0, len(df1), chunk_size)]
df2_chunks = [df_data[i:i+chunk_size] for i in range(0, len(df_data), chunk_size)]
# Perform the merge in chunks
merged_chunks = []
for chunk1, chunk2 in zip(df1_chunks, df2_chunks):
    merged_chunk = pd.merge(chunk1, chunk2, on='order_delivered_customer_date')
    merged_chunks.append(merged_chunk)
# Concatenate the merged chunks into the final result
final_result = pd.concat(merged_chunks)
#Join the dataframes 

df = final_result.merge(df_cat, on = 'product_category_name')
df.columns
Index(['order_id', 'customer_id', 'order_delivered_customer_date',
       'payment_value', 'product_id', 'price', 'product_category_name',
       'product_photos_qty', 'customer_unique_id', 'customer_city',
       'customer_state', 'geolocation_lat', 'geolocation_lng', 'Day', 'Month',
       'Year', 'product_category_name_english'],
      dtype='object')
#Exporting df_all
final_result.to_excel(r'/Users/ronaldcameron/Documents/Data Analytics/df_all.xlsx')
 
Heatmap

# Add labels, a legend, and change the size of the heatmap

a = plt.figure(figsize=(10, 10)) # figure size 
plt.matshow(df_all.corr(), fignum=a.number) # type of plot
plt.xticks(range(final_result.shape[1]), final_result.columns, fontsize=14, rotation=45) # x axis labels
plt.yticks(range(final_result.shape[1]), final_result.columns, fontsize=14) # y axis labels
cb = plt.colorbar() # add a colour legend (called colorbar)
cb.ax.tick_params(labelsize=14) # add font size
plt.title('Correlation Matrix', fontsize=14) # add title
Text(0.5, 1.0, 'Correlation Matrix')

# For some reason I could not get the heatmap to fill the full figure
# Create a subplot with matplotlib
f,ax = plt.subplots(figsize=(10,10))

# Create the correlation heatmap in seaborn by applying a heatmap onto the correlation matrix and the subplots defined above.
corr = sns.heatmap(sub.corr(), annot = True, ax = ax) # The `annot` argument allows the plot to 
#place the correlation coefficients onto the heatmap.

Create a correlation heatmap using seaborn:
final_result.columns
Index(['order_id', 'customer_id', 'order_delivered_customer_date',
       'payment_value', 'product_id', 'price', 'product_category_name',
       'product_photos_qty', 'customer_unique_id', 'customer_city',
       'customer_state', 'geolocation_lat', 'geolocation_lng', 'Day', 'Year'],
      dtype='object')
Getting Sales Trend

sales_trend = final_result.groupby(['Month', 'Year'])['payment_value'].sum().reset_index()
sales_trend.sort_values(['Year', 'Month'], inplace=True)
sales_trend.reset_index(drop=True, inplace=True)
sales_trend.head
<bound method NDFrame.head of     Month    Year  payment_value Price category
0    10.0  2016.0      441884.31     High price
1    11.0  2016.0      139915.60     High price
2    12.0  2016.0        2923.38     High price
3     1.0  2017.0      395412.11     High price
4     2.0  2017.0     2606455.05     High price
5     3.0  2017.0     5440280.35     High price
6     4.0  2017.0     3193601.30     High price
7     5.0  2017.0     5070494.37     High price
8     6.0  2017.0     4578179.97     High price
9     7.0  2017.0     5198220.52     High price
10    8.0  2017.0     8127630.20     High price
11    9.0  2017.0    10195854.88     High price
12   10.0  2017.0     7599270.18     High price
13   11.0  2017.0     7259891.02     High price
14   12.0  2017.0    13179225.53     High price
15    1.0  2018.0    12113499.40     High price
16    2.0  2018.0     9809535.68     High price
17    3.0  2018.0     7632972.89     High price
18    4.0  2018.0    13791262.65     High price
19    5.0  2018.0    10291976.47     High price
20    6.0  2018.0    11946263.57     High price
21    7.0  2018.0     8394306.04     High price
22    8.0  2018.0    11101525.65     High price
23    9.0  2018.0       59118.11     High price>
Scatterplots:
# Create a scatterplot for the "price" and "price per unit" columns in seaborn

sns.lmplot(x = 'Month', y = 'payment_value', data = final_result)
<seaborn.axisgrid.FacetGrid at 0x7f766f1936d0>

Pair Plots:
# Create a subset excluding the columns
sns.pairplot(sales_trend)
<seaborn.axisgrid.PairGrid at 0x7f7670977e20>

Categorical Plots:
sales_trend['Year'] = sales_trend['Year'].round().astype(int)
sales_trend['Month'] = sales_trend['Month'].round().astype(int)
sales_trend.head
<bound method NDFrame.head of     Month  Year  payment_value Price category   Sales Trend
0      10  2016      441884.31     High price     Low sales
1      11  2016      139915.60     High price     Low sales
2      12  2016        2923.38     High price     Low sales
3       1  2017      395412.11     High price     Low sales
4       2  2017     2606455.05     High price     Low sales
5       3  2017     5440280.35   Middle sales  Middle sales
6       4  2017     3193601.30     High price     Low sales
7       5  2017     5070494.37   Middle sales  Middle sales
8       6  2017     4578179.97     High price     Low sales
9       7  2017     5198220.52   Middle sales  Middle sales
10      8  2017     8127630.20   Middle sales  Middle sales
11      9  2017    10195854.88   Middle sales    High sales
12     10  2017     7599270.18   Middle sales  Middle sales
13     11  2017     7259891.02   Middle sales  Middle sales
14     12  2017    13179225.53   Middle sales    High sales
15      1  2018    12113499.40   Middle sales    High sales
16      2  2018     9809535.68   Middle sales  Middle sales
17      3  2018     7632972.89   Middle sales  Middle sales
18      4  2018    13791262.65   Middle sales    High sales
19      5  2018    10291976.47   Middle sales    High sales
20      6  2018    11946263.57   Middle sales    High sales
21      7  2018     8394306.04   Middle sales  Middle sales
22      8  2018    11101525.65   Middle sales    High sales
23      9  2018       59118.11     High price     Low sales>
# Create a pair plot 

fig = sns.histplot(sales_trend['Year'], bins = 3, kde = True)

fig_object = fig.get_figure()
fig_object.savefig('histogram.png', dpi=300, bbox_inches='tight')
The highest sales were in 2017

sales_trend.loc[sales_trend['payment_value'] < 5000000, 'Sales Trend'] = 'Low sales'
sales_trend.loc[(sales_trend['payment_value'] >= 5000000) & (sales_trend['payment_value'] < 10000000), 'Sales Trend'] = 'Middle sales'
sales_trend.loc[sales_trend['payment_value'] >= 10000000, 'Sales Trend'] = 'High sales'
sales_trend['Sales Trend'].value_counts(dropna = False)
Middle sales    9
Low sales       8
High sales      7
Name: Sales Trend, dtype: int64
sales_trend.head
<bound method NDFrame.head of     Month    Year  payment_value Price category   Sales Trend
0    10.0  2016.0      441884.31     High price     Low sales
1    11.0  2016.0      139915.60     High price     Low sales
2    12.0  2016.0        2923.38     High price     Low sales
3     1.0  2017.0      395412.11     High price     Low sales
4     2.0  2017.0     2606455.05     High price     Low sales
5     3.0  2017.0     5440280.35   Middle sales  Middle sales
6     4.0  2017.0     3193601.30     High price     Low sales
7     5.0  2017.0     5070494.37   Middle sales  Middle sales
8     6.0  2017.0     4578179.97     High price     Low sales
9     7.0  2017.0     5198220.52   Middle sales  Middle sales
10    8.0  2017.0     8127630.20   Middle sales  Middle sales
11    9.0  2017.0    10195854.88   Middle sales    High sales
12   10.0  2017.0     7599270.18   Middle sales  Middle sales
13   11.0  2017.0     7259891.02   Middle sales  Middle sales
14   12.0  2017.0    13179225.53   Middle sales    High sales
15    1.0  2018.0    12113499.40   Middle sales    High sales
16    2.0  2018.0     9809535.68   Middle sales  Middle sales
17    3.0  2018.0     7632972.89   Middle sales  Middle sales
18    4.0  2018.0    13791262.65   Middle sales    High sales
19    5.0  2018.0    10291976.47   Middle sales    High sales
20    6.0  2018.0    11946263.57   Middle sales    High sales
21    7.0  2018.0     8394306.04   Middle sales  Middle sales
22    8.0  2018.0    11101525.65   Middle sales    High sales
23    9.0  2018.0       59118.11     High price     Low sales>
sales_trend.columns
Index(['Month', 'Year', 'payment_value', 'Price category', 'Sales Trend'], dtype='object')
# Create a categorical plot in seaborn using the price categories created above

sns.set(style="ticks")
g = sns.catplot(x="Month", y="payment_value", hue="Sales Trend", data=sales_trend)

The sales trend is not as I expected. The highest sales were in the month of April

# fig = g.get_figure()
g.savefig("out.png") 
Finding Product Sales
# Group the data by product_id and calculate the sum of payment_value
product_sales_volume = df.groupby('product_id')['payment_value'].sum()
# Find the product with the highest sales volume
product_with_highest_volume = product_sales_volume.idxmax()
# Get the corresponding product_category_name
category_of_highest_volume = df.loc[final_result['product_id'] == product_with_highest_volume, 'product_category_name_english'].iloc[0]
print("Product with the highest sales volume:")
print("Product ID:", product_with_highest_volume)
print("Product Category:", category_of_highest_volume)
Product with the highest sales volume:
Product ID: 08574b074924071f4e201e151b152b4e
Product Category: housewares
Product with the highest sales volume are housewares

# Group the data by product_id, Year, and Month and calculate the sum of payment_value
sales_by_product = df.groupby(['product_id', 'product_category_name_english', 'Month'])['payment_value'].sum().reset_index()
# Create a pivot table to reshape the data for visualization
pivot_table = pd.pivot_table(sales_by_product, values='payment_value', index='product_category_name_english', columns=['Month'], aggfunc='sum', fill_value=0)
print(pivot_table)
Month                               1.0         2.0        3.0         4.0   \
product_category_name_english                                                 
agro_industry_and_commerce          0.00    10548.78   10158.64    27383.58   
air_conditioning                12397.66    13821.16   22583.47    55582.42   
art                             18772.36        0.00       0.00     9714.10   
arts_and_craftmanship               0.00        0.00       0.00        0.00   
audio                           21687.46     2518.88    6405.63        0.00   
...                                  ...         ...        ...         ...   
stationery                     463965.53   250871.62  154071.25   314528.63   
tablets_printing_image              0.00     5263.18       0.00        0.00   
telephony                      158399.97   212854.30  131583.21   321601.89   
toys                           428418.72   186642.05  340262.26   562988.45   
watches_gifts                  698646.55  1261367.33  502616.61  1075447.03   

Month                                5.0         6.0         7.0        8.0   \
product_category_name_english                                                  
agro_industry_and_commerce       27222.80        0.00        0.00   23874.90   
air_conditioning                  8746.65    18879.86   116528.04   85664.15   
art                              28574.77    16638.16    12342.00   23050.23   
arts_and_craftmanship                0.00        0.00    20311.20       0.00   
audio                            34323.16    16546.24     4547.16   78957.78   
...                                   ...         ...         ...        ...   
stationery                      154282.76   488976.26    80383.96  407822.67   
tablets_printing_image               0.00    37421.88        0.00       0.00   
telephony                       170396.74   800229.98   117730.89  233397.67   
toys                            513013.13   570296.38   441316.62  681846.03   
watches_gifts                  1354672.75  1401702.98  2084316.47  712320.22   

Month                               9.0        10.0       11.0        12.0  
product_category_name_english                                               
agro_industry_and_commerce      27590.64   83884.68       0.00  2149349.07  
air_conditioning                    0.00       0.00       0.00    25831.22  
art                                 0.00       0.00       0.00        0.00  
arts_and_craftmanship               0.00       0.00       0.00        0.00  
audio                               0.00   59832.16  125098.67        0.00  
...                                  ...        ...        ...         ...  
stationery                      66570.63   49408.90   53981.62   261407.36  
tablets_printing_image         100514.31       0.00   14739.20        0.00  
telephony                      124953.68   68951.31  184985.93   178859.11  
toys                           241554.92  992525.53  553485.71   896124.44  
watches_gifts                  618284.38  811450.46  575345.77  1163292.71  

[69 rows x 12 columns]
# Export the pivot table to a CSV file
pivot_table.to_csv('sales_pivot.csv', index=True)
# Create a pair plot 

a = sns.histplot(sales_by_product['Month'], bins = 3, kde = True)

 
# Plot the product sales
pivot_table.plot(kind='line', figsize=(30, 40))

# Set the labels and title
plt.xlabel('product_category_name_english')
plt.ylabel('payment_value')
plt.title('Product Sales Over Time')

# Show the plot
plt.show()
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
/var/folders/8w/y0j0hy213tj11t4fgrr14y1h0000gn/T/ipykernel_22011/1366578627.py in <module>
      3 
      4 # Set the labels and title
----> 5 plt.xlabel('product_category_name_english')
      6 plt.ylabel('payment_value')
      7 plt.title('Product Sales Over Time')

AttributeError: 'AxesSubplot' object has no attribute 'xlabel'

#Importing Category Names
df_sales = pd.read_excel(r'/Users/ronaldcameron/Documents/Data Analytics/Achievement 6 - Data/sales_pivot.xlsx', sheet_name = 'sales_by_month')
df_sales.columns
Index(['Sales by Month', 'Revenue'], dtype='object')
b = sns.lmplot(x = 'Sales by Month', y = 'Revenue', data = df_sales)

I was not expecting sales to drop toward the end of the year

# fig = g.get_figure()
b.savefig("revenue.png") 
